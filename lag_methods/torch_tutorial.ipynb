{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f54a925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2.0\n",
      "y = 11.0\n",
      "dy/dx = 7.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Scalar example\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2 + 3*x + 1   # y = x² + 3x + 1\n",
    "\n",
    "y.backward()  # dy/dx\n",
    "\n",
    "print(\"x =\", x.item())\n",
    "print(\"y =\", y.item())\n",
    "print(\"dy/dx =\", x.grad.item())  # Should be 2x + 3 = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b12db36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([0.8707, 0.9710, 0.6764], requires_grad=True)\n",
      "Gradient dy/dx = tensor([2., 4., 1.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)  # vector\n",
    "A = torch.tensor([[2., 1., 0.],\n",
    "                  [0., 3., 1.]], requires_grad=False)\n",
    "\n",
    "y = (A @ x).sum()  # scalar output\n",
    "\n",
    "y.backward()\n",
    "print(\"x =\", x)\n",
    "print(\"Gradient dy/dx =\", x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a6ae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian:\n",
      " tensor([[ 2.0000,  0.0000],\n",
      "        [ 2.0000,  1.0000],\n",
      "        [ 0.0000, -0.4161]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "\n",
    "y = torch.stack([x[0]**2, x[0]*x[1], torch.sin(x[1])])\n",
    "\n",
    "# Compute full Jacobian\n",
    "J = torch.autograd.functional.jacobian(lambda v: torch.stack([v[0]**2, v[0]*v[1], torch.sin(v[1])]), x)\n",
    "\n",
    "print(\"Jacobian:\\n\", J)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc261dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th derivative at x=1: 24.493920508725523\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "def nth_derivative(f, x, n):\n",
    "    \"\"\"\n",
    "    f: function mapping scalar tensor -> scalar tensor\n",
    "    x: scalar tensor with requires_grad=True\n",
    "    n: order (>=1)\n",
    "    \"\"\"\n",
    "    y = f(x)\n",
    "    for k in range(n):\n",
    "        # Always create_graph to enable higher-order grads\n",
    "        (y,) = torch.autograd.grad(y, x, create_graph=True)\n",
    "    return y  # n-th derivative evaluated at x\n",
    "\n",
    "# Example: f(x) = sin(x^3); compute d^5 f / dx^5 at x = 1.0\n",
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "f = lambda t: torch.sin(t**3)\n",
    "d5 = nth_derivative(f, x, 5)\n",
    "print(\"5th derivative at x=1:\", d5.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c211220e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian shape: torch.Size([2, 2])\n",
      "tensor([[20.3628,  9.7653],\n",
      "        [ 9.7653,  1.0907]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd.functional import hessian\n",
    "\n",
    "# f: R^2 -> R\n",
    "def f(v):\n",
    "    x, y = v\n",
    "    return x**3 * y**2 + torch.sin(x*y)\n",
    "\n",
    "# Point\n",
    "v = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "\n",
    "H = hessian(lambda z: f(z), v)\n",
    "print(\"Hessian shape:\", H.shape)   # (2, 2)\n",
    "print(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ddf86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∂³f/∂x∂y∂x at (1,2): 22.027397638885844\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "y = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "def fxy(x, y):\n",
    "    return x**3 * y**2 + torch.sin(x*y)\n",
    "\n",
    "# First w.r.t. x\n",
    "g_x, = torch.autograd.grad(fxy(x, y), x, create_graph=True)\n",
    "# Then w.r.t. y\n",
    "g_xy, = torch.autograd.grad(g_x, y, create_graph=True)\n",
    "# Then w.r.t. x again\n",
    "g_xyx, = torch.autograd.grad(g_xy, x, create_graph=True)\n",
    "\n",
    "print(\"∂³f/∂x∂y∂x at (1,2):\", g_xyx.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
